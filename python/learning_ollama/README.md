# playing with ollama

local LLM inference

## models

* Llama 2: excels at text generation, question answering and text classification due to its large training dataset
* Stablelm-zephyr: finetuned for instruction following and q&a related tasks
* Phi3: specialises in logical and mathematical reasoning with long context
* Mistral: a LLM model that outperforms Llama 2 on every benchmark, but significantly larger in size
* Orca-mini: general purpose LLM model
* Vicuna: finetuned for LLM-powered chatbot purposes
* CodeGeeX4: multilingual code generation and completion
* CodeLlama: code generation and explanation built on Llama 2
* Starcoder: code generation model trained on 80+ programming languages

## see more

* [ollama models](https://ollama.com/library#:~:text=CodeGemma%20is%20a%20collection%20of,mathematical%20reasoning%2C%20and%20instruction%20following.)